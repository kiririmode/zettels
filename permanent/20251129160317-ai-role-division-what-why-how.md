---
id: 2025-11-29-160317
title: AI連携開発における役割分担の原則
created: 2025-11-29 16:03:17
updated: 2025-11-29 16:03:17
tags:
  - zettel
  - ai
  - development-methods
  - design
source:
  type: article
  ref: "食べログ技術ブログ - 実装の9割をAIに任せる"
---

## 要約（Summary）

- 人間は「What（何を作るか）」と「Why（なぜ作るか）」を定義し、AIは「How（どう作るか）」を実装する役割分担が効果的である。
- 適切な役割分担とガードレールにより、定型的な実装作業の大部分をAIに委譲できる（事例では約90%の委譲が可能と報告される）。
- 人間は戦略設計・意図の記録・品質担保に注力し、AIは反復的な実装、テスト、ドキュメント作成を担当する。

## 本文（Body）

AIと人間が協業する開発では、単にAIにタスクを投げるだけでは成果が安定しない。重要なのは、両者の得意分野を分離して期待値と検証方法を明確にすることだ。

### 背景・問題意識

近年のツール進化により、コード生成やテスト自動生成は高度に可能になった。しかし「丸投げ」型の運用では、実装理由が残らずレビューで議論が起きやすく、バグ修正時に設計意図が失われる。これを防ぐため、意図（Why）を明確にし、仕様（What）を一次成果物として保持する運用が必要になる。

### 中核となる主張

「人間がWhat/Whyを定義し、AIがHowを実装する」という分業は、次の利点をもたらす。

- 意図の永続化: 仕様を記録し続けることで、将来の変更時に決定理由が参照できる。
- 品質担保の明確化: 人間はレビューとガードレール設計に集中し、AIの生成物は自動テストや契約テストで検証する。
- 効率化: 定型実装の工数を削減し、設計や要件定義のコストにリソースを振れる。

### 実務での具体的ワークフロー（例）

1. 要件定義（What）: プロダクト／仕様文書に対してAcceptance Criteriaを記載する。
2. 意図記録（Why）: なぜその仕様なのかを短くメモ（前提、非機能要件、制約）として残す。
3. タスク分解: 実装タスクを小さな単位に分割し、各タスクに受け入れ基準をつける。
4. AI実装（How）: 各タスクに対してAIに実装を依頼。プロンプトには入力/出力の契約、失敗時の振る舞い、テスト仕様を含める。
5. 自動検証: CIで契約テスト・ユニットテストを実行し、仕様準拠を確認する。
6. 人間によるレビューと承認: 重要ロジックやアーキテクチャ変更は人間がレビューし承認する。

### 典型的な役割分担一覧

- 人間（What/Why）
  - プロダクトビジョン、ユーザーストーリー、Acceptance Criteria
  - セキュリティ／プライバシー方針、アーキテクチャ決定
  - レビュー、テストポリシー、運用ルールの策定

- AI（How）
  - 実装のスケルトン生成（コントローラ/サービス/DAO等）
  - テストコード（ユニット/統合）の生成
  - ドキュメント・APIシグネチャの更新

### 具体例：食べログAPIのワークフロー（簡略）

- 人間：予約のビジネスルール（同時予約数、同一時間帯の制約、キャンセルポリシー）を仕様化
- 人間：APIの成功・失敗ケースと整合性チェック条件（Acceptance Criteria）を記載
- AI：コントローラ/Usecase/Repositoryの雛形を生成し、テストケースを合わせて作成
- 人間：アーキテクチャ的に重要な部分（トランザクション境界、外部API呼び出しの耐障害性）をレビュー・修正

### 実践的なプロンプトテンプレート（短縮版）

以下はAI（コーディングエージェント）に渡す最小限のテンプレート例。必要に応じて詳細化する。

```
Role: TypeScript Developer
Task: Implement endpoint POST /reservations
Contract: Request { userId: string, tableId: string, startAt: ISOString, durationMinutes: number }
Acceptance Criteria: 1) rejects overlapping reservations for same table; 2) returns 201 with reservation id on success
Notes: Business rule: same user can have at most 3 future reservations
Test: Provide unit tests that cover success, overlap rejection, and max-reservation rule
```

上記テンプレートを使うことで、AIが出すコードを自動テストで検証しやすくなる。

### レビュー時のチェックリスト（レビュワー向け）

1. 仕様との整合性: 実装がAcceptance Criteriaを満たしているか？
2. 副作用の明示: 外部APIやDB更新の副作用は明確か？
3. エラーパスの扱い: 異常系の返却は仕様通りか？
4. テストの網羅: 生成されたテストが主要なケースをカバーしているか？
5. 可読性と保守性: 名前や構造はチーム規約に沿っているか？

### リスクと緩和策

- リスク: AIが意図を誤解して微妙なビジネスロジックを破る
  - 緩和策: 小さな単位でタスクを分割し、受け入れ基準を自動テスト化する
- リスク: ドメイン知識の伝達コストが高い
  - 緩和策: ドメインの要点を短いFAQ形式でまとめ、テンプレート化する

### 成功指標（KPI）

- 実装委譲率: AIが担当したPR数 / 全PR数
- バグ回帰率: AI実装によるバグの発生率（人間実装との比較）
- レビュー時間: 1PRあたりの平均レビュー時間

## 関連ノート（Links）

- [[20251129160318-autonomous-ai-vs-coding-assistant|自律型AIとコーディングアシスタントの使い分け]]
- [[20251129160319-ai-guardrails|AI開発におけるガードレールの重要性]]
- [[20251129160320-ai-task-granularity|AIへのタスク粒度と効率の関係]]
- [[20251206000000-ai-coding-invisible-problems|AIコーディング時代の「見えない問題」]]

## To-Do / 次に考えること

- [ ] 自分のプロジェクトでWhat/Whyを明文化する練習をする
- [ ] AIに渡す「指示書」のテンプレートをプロジェクト標準に落とし込む
- [ ] チームの暗黙知（設計思想、コーディング規約）をドキュメント化する

